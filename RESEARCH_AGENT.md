# Company Research Agent

## Overview

The Company Research Agent is an automated web research tool that researches companies for sustainability and ESG data. It generates reports in the same TXT format used by the project management system, making it compatible with the existing analysis pipeline.

## How It Works

### 1. User Input
Users enter company names (up to 4 companies) in the **Deep Research Engine** module.

### 2. Automated Research
For each company, the agent performs targeted web searches across 5 categories:
- **Emissions**: Carbon reduction commitments, net-zero targets, climate pledges
- **Investments**: Sustainability investments, renewable energy funds, climate initiatives
- **Purchases**: Equipment purchases, clean energy infrastructure, renewable assets
- **Pilots**: Pilot projects, carbon capture initiatives, sustainability programs
- **Environments**: Project environments, sustainability facilities, green buildings

### 3. Report Generation
The agent generates 5 TXT files (one per category) containing:
- Company name
- Source URLs
- Relevant excerpts from web search results
- Structured in the same format as manually uploaded files

### 4. Storage & Integration
- Reports are automatically uploaded to Supabase Storage (`sustainability-reports` bucket)
- A new project is created with references to all uploaded files
- Files can then be analyzed using the existing analysis pipeline

## API Endpoints

### POST /api/research-companies

Researches companies and generates report files.

**Request Body:**
```json
{
  "companies": [
    { "name": "Tesla" },
    { "name": "Apple" },
    { "name": "Microsoft" }
  ],
  "projectId": "uuid-of-project"
}
```

**Response:**
```json
{
  "success": true,
  "message": "Successfully researched 3 companies",
  "uploadedFiles": 5
}
```

## Web Search Integration

The agent uses the **Tavily API** for web search:
- Advanced search depth for comprehensive results
- Up to 10 results per query
- Extracts title, URL, and content snippets

### Setup

1. Sign up for a Tavily API key at https://tavily.com
2. Add to your `.env.local`:
   ```
   TAVILY_API_KEY=tvly-your-api-key
   ```

## Output Format

Each generated TXT file follows this structure:

```
Company: Tesla
==================================================

Title: Tesla announces net-zero commitment by 2030
Source: https://tesla.com/sustainability
Content: Tesla has committed to achieving net-zero emissions across its entire value chain by 2030...

--------------------------------------------------

Title: Tesla's renewable energy investments reach $5B
Source: https://news.tesla.com/investments
Content: The company announced $5 billion in renewable energy investments...

--------------------------------------------------

[More results...]
```

## Data Flow

```
User Input (Company Names)
    ↓
Create Project
    ↓
Research Agent
    ├─ Web Search (Tavily API)
    ├─ Extract Results
    └─ Format as TXT
    ↓
Upload to Supabase Storage
    ├─ sustainability-reports/emissions.txt
    ├─ sustainability-reports/investments.txt
    ├─ sustainability-reports/machine_purchases.txt
    ├─ sustainability-reports/pilot_projects.txt
    └─ sustainability-reports/project_environments.txt
    ↓
Create project_files Records
    ↓
Update sustainability_projects
    ↓
Ready for Analysis
```

## Frontend Integration

The **DeepResearchEngine** component (`src/components/modules/DeepResearchEngine.tsx`):
1. Accepts up to 4 company names
2. Creates a project via `/api/sustainability/projects`
3. Calls `/api/research-companies` with project ID
4. Displays success message with file count
5. Stores query in ResearchContext for display

## Database Schema

### sustainability_projects
- Stores project metadata
- References to uploaded file IDs
- Analysis status tracking

### project_files
- Stores file metadata (path, size, type)
- Links files to projects
- Tracks upload status

### analysis_results
- Generated by analysis pipeline
- One row per company (normalized view)
- Boolean flags for each attribute

### analysis_details
- Generated by analysis pipeline
- One row per attribute per company
- Full text and source information

### analysis_diagnostics
- Generated by analysis pipeline
- Count of mentions per category per company

## Testing

To test the research agent:

1. Start the development server:
   ```bash
   npm run dev
   ```

2. Ensure Supabase is running:
   ```bash
   npx supabase start
   ```

3. Set up your Tavily API key in `.env.local`

4. Navigate to **Deep Research Engine** in the UI

5. Enter company names (e.g., "Tesla", "Apple", "Microsoft")

6. Click "Run Deep Research"

7. Wait for completion (may take 1-2 minutes per company)

8. Check the **Projects** module to see the generated project

9. Run analysis on the project to see results

## Limitations

1. **Web Search Required**: Requires Tavily API key (free tier available)
2. **Rate Limits**: Subject to Tavily API rate limits
3. **Quality**: Results depend on web search quality and availability
4. **Processing Time**: ~1-2 minutes per company for comprehensive research
5. **Storage**: Generated files consume Supabase storage quota

## Future Improvements

- [ ] Add progress indicators during research
- [ ] Support for custom search queries per category
- [ ] Caching of search results to avoid duplicate searches
- [ ] Alternative search providers (Google, Bing, etc.)
- [ ] PDF/HTML output formats
- [ ] Scheduled/recurring research for tracking changes over time
- [ ] Export research data as JSON/CSV
- [ ] Integration with LLM for summarization and extraction
- [ ] Comparison view between multiple research runs

## Related Files

- `/src/app/api/research-companies/route.ts` - API endpoint
- `/src/lib/web-search.ts` - Tavily API wrapper
- `/src/components/modules/DeepResearchEngine.tsx` - UI component
- `/supabase/migrations/20251019000000_add_sustainability_projects.sql` - Database schema
